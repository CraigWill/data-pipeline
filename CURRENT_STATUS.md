# å½“å‰ç³»ç»ŸçŠ¶æ€æ€»ç»“

## æ—¥æœŸ
2026-02-12

## ç³»ç»Ÿç»„ä»¶çŠ¶æ€

### âœ… Docker æœåŠ¡ï¼ˆå…¨éƒ¨è¿è¡Œä¸­ï¼‰
- **Flink JobManager**: http://localhost:8081
- **Flink TaskManager**: 1 ä¸ªå®ä¾‹ï¼Œ4 ä¸ªä»»åŠ¡æ§½
- **Kafka**: localhost:9092
- **Kafka UI**: http://localhost:8080
- **Zookeeper**: localhost:2181
- **Oracle 11g**: localhost:1521 (helowin å®ä¾‹)

### âœ… Flink ä½œä¸š
- **ä½œä¸š ID**: e0b3bb0c6fb9f659b5a42236545c55bd
- **ä½œä¸šåç§°**: Realtime Data Pipeline
- **çŠ¶æ€**: RUNNING
- **ä¸»ç±»**: FlinkPipelineMain
- **å¹¶è¡Œåº¦**: 2

## è¾“å‡ºæ–‡ä»¶çŠ¶æ€

### âœ… CSV æ–‡ä»¶æ­£åœ¨ç”Ÿæˆ
**ä½ç½®**: `/opt/flink/output/cdc/2026-02-12--01/`

**æ–‡ä»¶ç¤ºä¾‹**:
```
.part-c128eebd-56c1-4d5c-acc2-afad732577fc-0.inprogress.*
.part-c128eebd-56c1-4d5c-acc2-afad732577fc-1.inprogress.*
```

**å†…å®¹ç¤ºä¾‹**:
```csv
2026-02-12 01:41:57,trans_info,UPDATE,"name=sample_name_0","id=0","value=712","timestamp=1770860517412",
2026-02-12 01:42:02,trans_info,INSERT,"name=sample_name_1","id=1","value=369","timestamp=1770860522758",
2026-02-12 01:42:07,trans_info,INSERT,"name=sample_name_2","id=2","value=410","timestamp=1770860527760",
```

## é‡è¦å‘ç°

### âš ï¸ DataHubSource æ˜¯ Mock å®ç°
**é—®é¢˜**: `DefaultDataHubClient.getRecords()` æ€»æ˜¯è¿”å›ç©ºåˆ—è¡¨

**ä»£ç ä½ç½®**: `src/main/java/com/realtime/pipeline/datahub/client/DefaultDataHubClient.java:149`

```java
public List<java.util.Map<String, Object>> getRecords(...) {
    // æ¨¡æ‹Ÿä»DataHubè·å–è®°å½•
    // è¿”å›ç©ºåˆ—è¡¨è¡¨ç¤ºå½“å‰æ²¡æœ‰æ–°æ•°æ®
    return new java.util.ArrayList<>();  // âš ï¸ æ€»æ˜¯è¿”å›ç©º
}
```

**å½±å“**:
- FlinkPipelineMain ä½¿ç”¨ DataHubSourceï¼Œä½†æ— æ³•ä» Kafka è¯»å–çœŸå®æ•°æ®
- å½“å‰è¾“å‡ºçš„ CSV æ–‡ä»¶æ¥è‡ªä¹‹å‰è¿è¡Œçš„ SimpleCDCAppï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰
- å‘é€åˆ° Kafka çš„æµ‹è¯•æ•°æ®æ— æ³•è¢«æ¶ˆè´¹

### âœ… SimpleCDCApp æ­£å¸¸å·¥ä½œ
- ä½¿ç”¨è‡ªå·±çš„ MockCDCSource ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
- ç›´æ¥å†™å…¥ CSV æ–‡ä»¶
- ä¸ä¾èµ– Kafka æˆ– DataHub

## å¯ç”¨çš„åº”ç”¨ç¨‹åº

### 1. SimpleCDCApp âœ… æ¨èç”¨äºæ¼”ç¤º
**ä¸»ç±»**: `com.realtime.pipeline.SimpleCDCApp`

**ç‰¹ç‚¹**:
- ä½¿ç”¨é¡¹ç›®é…ç½®ç±»ï¼ˆDatabaseConfig, OutputConfigï¼‰
- ä½¿ç”¨é¡¹ç›®æ¨¡å‹ç±»ï¼ˆChangeEvent, ProcessedEventï¼‰
- ç”Ÿæˆæ¨¡æ‹Ÿ CDC æ•°æ®
- ç›´æ¥å†™å…¥ CSV æ–‡ä»¶
- ä¸éœ€è¦å¤–éƒ¨æ•°æ®æº

**å¯åŠ¨æ–¹å¼**:
```bash
./submit-to-flink.sh simple
# æˆ–
./submit-to-flink.sh 1
```

### 2. JdbcCDCApp âš ï¸ éœ€è¦æ•°æ®åº“è¿æ¥
**ä¸»ç±»**: `com.realtime.pipeline.JdbcCDCApp`

**ç‰¹ç‚¹**:
- ä½¿ç”¨ JDBC è½®è¯¢æ–¹å¼ç›‘æ§æ•°æ®åº“
- è¿æ¥ Oracle æ•°æ®åº“ (localhost:1521)
- ç›‘æ§ helowin.trans_info è¡¨
- å¦‚æœæ— æ³•è¿æ¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼

**å¯åŠ¨æ–¹å¼**:
```bash
./submit-to-flink.sh jdbc
# æˆ–
./submit-to-flink.sh 2
```

### 3. FlinkPipelineMain âš ï¸ DataHubSource æ˜¯ Mock
**ä¸»ç±»**: `com.realtime.pipeline.FlinkPipelineMain`

**ç‰¹ç‚¹**:
- å®Œæ•´çš„ç®¡é“æ¶æ„
- åŒ…å«ç›‘æ§ã€å‘Šè­¦ã€å¥åº·æ£€æŸ¥
- ä½¿ç”¨ DataHubSourceï¼ˆä½†æ˜¯ mock å®ç°ï¼‰
- éœ€è¦é…ç½®æ–‡ä»¶ `application.yml`

**å¯åŠ¨æ–¹å¼**:
```bash
./submit-to-flink.sh main
# æˆ–
./submit-to-flink.sh 3
```

**å½“å‰é—®é¢˜**: DataHubSource ä¸ä¼šä» Kafka è¯»å–çœŸå®æ•°æ®

## æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶

### åœ¨å®¹å™¨å†…æŸ¥çœ‹
```bash
# åˆ—å‡ºæ‰€æœ‰è¾“å‡ºæ–‡ä»¶
docker exec realtime-pipeline-taskmanager-1 \
  find /opt/flink/output/cdc -type f

# æŸ¥çœ‹æ–‡ä»¶å†…å®¹
docker exec realtime-pipeline-taskmanager-1 \
  sh -c 'cat /opt/flink/output/cdc/2026-02-12--01/.part-*.inprogress.* | head -20'

# å®æ—¶æŸ¥çœ‹æ–°æ•°æ®
docker exec realtime-pipeline-taskmanager-1 \
  sh -c 'tail -f /opt/flink/output/cdc/2026-02-12--01/.part-*.inprogress.*'
```

### å¤åˆ¶åˆ°æœ¬åœ°
```bash
# åˆ›å»ºæœ¬åœ°ç›®å½•
mkdir -p output/cdc

# ä»å®¹å™¨å¤åˆ¶æ–‡ä»¶
docker cp realtime-pipeline-taskmanager-1:/opt/flink/output/cdc/. output/cdc/

# æŸ¥çœ‹æœ¬åœ°æ–‡ä»¶
ls -la output/cdc/
cat output/cdc/2026-02-12--01/part-*
```

## Kafka æµ‹è¯•æ•°æ®

### å‘é€æµ‹è¯•æ•°æ®åˆ° Kafka
```bash
./send-test-data-to-kafka.sh
```

### éªŒè¯ Kafka ä¸­çš„æ•°æ®
```bash
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic cdc-events \
  --from-beginning \
  --max-messages 10
```

## ä½œä¸šç®¡ç†

### æŸ¥çœ‹è¿è¡Œä¸­çš„ä½œä¸š
```bash
docker exec flink-jobmanager flink list
```

### å–æ¶ˆä½œä¸š
```bash
docker exec flink-jobmanager flink cancel <job-id>
```

### æŸ¥çœ‹æ—¥å¿—
```bash
# JobManager æ—¥å¿—
docker logs -f flink-jobmanager

# TaskManager æ—¥å¿—
docker logs -f realtime-pipeline-taskmanager-1
```

## ä¸‹ä¸€æ­¥å»ºè®®

### é€‰é¡¹ 1: ä½¿ç”¨ SimpleCDCAppï¼ˆæ¨èï¼‰
æœ€ç®€å•çš„æ–¹å¼ï¼Œå·²ç»åœ¨ç”Ÿæˆ CSV æ–‡ä»¶ã€‚

```bash
# å–æ¶ˆå½“å‰ä½œä¸š
docker exec flink-jobmanager flink cancel e0b3bb0c6fb9f659b5a42236545c55bd

# æäº¤ SimpleCDCApp
./submit-to-flink.sh simple
```

### é€‰é¡¹ 2: å®ç°çœŸå®çš„ Kafka Consumer
ä¿®æ”¹ `DefaultDataHubClient.getRecords()` ä»¥ä» Kafka çœŸæ­£è¯»å–æ•°æ®ã€‚

éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶:
- `src/main/java/com/realtime/pipeline/datahub/client/DefaultDataHubClient.java`

### é€‰é¡¹ 3: ä½¿ç”¨ Flink Kafka Connector
æ›¿æ¢ DataHubSource ä¸º Flink å®˜æ–¹çš„ Kafka Connectorã€‚

## é…ç½®æ–‡ä»¶

### å½“å‰ä½¿ç”¨çš„é…ç½®
- **ä½ç½®**: `/opt/flink/conf/application.yml` (å®¹å™¨å†…)
- **æœ¬åœ°å‰¯æœ¬**: `application-local.yml`

### å…³é”®é…ç½®
```yaml
datahub:
  endpoint: kafka://kafka:9092
  topic: cdc-events
  consumerGroup: flink-consumer-group
  startPosition: LATEST  # âš ï¸ åªè¯»å–æ–°æ¶ˆæ¯

output:
  path: /opt/flink/output/cdc
  format: csv
```

## æ€»ç»“

âœ… **æ­£å¸¸å·¥ä½œçš„éƒ¨åˆ†**:
- Flink é›†ç¾¤è¿è¡Œæ­£å¸¸
- SimpleCDCApp ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®å¹¶å†™å…¥ CSV
- CSV æ–‡ä»¶æ­£åœ¨ç”Ÿæˆ
- Kafka æœåŠ¡æ­£å¸¸

âš ï¸ **éœ€è¦æ³¨æ„çš„éƒ¨åˆ†**:
- DataHubSource æ˜¯ mock å®ç°ï¼Œä¸ä¼šä» Kafka è¯»å–çœŸå®æ•°æ®
- FlinkPipelineMain è™½ç„¶è¿è¡Œï¼Œä½†æ²¡æœ‰å¤„ç† Kafka æ•°æ®
- å½“å‰ CSV è¾“å‡ºæ¥è‡ªä¹‹å‰çš„ SimpleCDCApp

ğŸ’¡ **å»ºè®®**:
ä½¿ç”¨ SimpleCDCApp è¿›è¡Œæ¼”ç¤ºå’Œæµ‹è¯•ï¼Œå®ƒèƒ½æ­£å¸¸ç”Ÿæˆ CSV æ–‡ä»¶ã€‚
